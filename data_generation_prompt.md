# AI Agent Prompt: Kernel Fusion Task Generator

You are an AI agent tasked with creating and testing fused kernel implementations. Your goal is to generate kernel fusion tasks, implement them in both PyTorch and Triton, and benchmark their performance.

## Task Overview
You will be working in a cycle to:
1. Generate fusion tasks
2. Implement them in Python and Triton
3. Test and benchmark
4. Either succeed and save, or fail and retry (up to 3 attempts per task)
5. Repeat the cycle

## Step-by-Step Instructions

### Step 1: Generate Fusion Task
First, run the task generator:
```bash
python generate_fusion_task.py
```
Read the output carefully. It will give you a list of kernel operations to fuse together.

### Step 2: Create Implementation File
Create a single Python file with the following structure:

#### File Naming Convention
Name your file: `XXX_fused_kernels.py` where XXX is a 3-digit number (e.g., `001_fused_kernels.py`, `002_fused_kernels.py`)

#### Required Structure
```python
"""Fused Kernels: [DESCRIPTION OF OPERATIONS]"""

# <PYTHON>
import torch
import torch.nn.functional as F

def fused_kernel_pytorch(params):
    """
    PyTorch or Python implementation combining:
    1. [Operation 1]
    2. [Operation 2] 
    3. [Operation 3]
    """
    # Implement the operations here, no need for comment
    # Use the operations from the generated task
    pass

# </PYTHON>

# <TRITON>
import torch
import triton
import triton.language as tl

@triton.jit
def fused_kernel_triton(
params
):
    """
    Triton fused kernel implementation
    """
    # Implement the fused operations here
    pass

def fused_kernel_triton_wrapper(params):
    """
    Wrapper for the Triton kernel
    """
    # Implementation here
    pass

# </TRITON>

# <TEST>
import torch
import time

def test_performance(pytorch_func, triton_func, inputs, num_runs=50):
    """Test performance of both implementations"""
    # Implementation here
    pass

# </TEST>

# Main execution block
if __name__ == '__main__':
    print("=== ATTEMPT [X]: [DESCRIPTION] ===")
    
    # Your main execution code here
    # Include attempt counting and comprehensive reporting
```

#### Delimiter Requirements
- **PYTHON**: Contains PyTorch implementation
- **TRITON**: Contains Triton kernel and wrapper
- **TEST**: Contains testing utilities
- **Main execution**: Everything after the delimiters

### Step 3: Implementation Guidelines

#### PyTorch Implementation
- Make it functional and efficient
- Handle matrix dimensions correctly

#### Triton Implementation
- Use `@triton.jit` decorator
- Implement proper blocking strategy
- Handle memory access patterns correctly

#### Testing
- Generate appropriate test inputs
- Measure performance with timing
- Compare outputs between implementations
- Handle errors gracefully

### Step 4: Execution and Testing
Run your file:
```bash
python XXX_fused_kernels.py
```

Read the output carefully. Look for:
- Success/failure of both implementations
- Performance timing
- Any error messages

### Step 5: Success Criteria and Retry Logic

#### Success Criteria
- Both PyTorch and Triton implementations execute successfully
- Triton is faster than PyTorch
- Both produce correct output shapes

#### Retry Logic (Up to 3 attempts per task)
**ATTEMPT 1**: Initial implementation
**ATTEMPT 2**: Fix any issues from attempt 1
**ATTEMPT 3**: Final attempt to fix remaining issues

If all 3 attempts fail:
1. Delete the failed file
2. Go back to Step 1 (generate new task)
3. Start fresh with new task

#### Attempt Tracking
Always show attempt number in output:
```python
print("=== ATTEMPT 1: [DESCRIPTION] ===")
# or
print("=== ATTEMPT 2: [DESCRIPTION] ===")
# or  
print("=== ATTEMPT 3: [DESCRIPTION] ===")
```

### Step 6: Success Actions
When you succeed (both execute AND Triton is faster):
1. Move the successful file to the data folder:
   ```bash
   mv XXX_fused_kernels.py data/
   ```
2. Continue the cycle by going back to Step 1

### Step 7: Failure Actions
When all 3 attempts fail:
1. Delete the failed file:
   ```bash
   rm XXX_fused_kernels.py
   ```
2. Go back to Step 1 to generate a new task

## Important Notes

- **Keep track of attempt numbers explicitly**
- **Always test with python before proceeding**
- **Move successful files to data/ folder**
- **Delete failed files after 3 attempts**
- **Continue the cycle indefinitely**

## Example Output Format
Your final report should look like:
```
============================================================
FINAL TEST REPORT - ATTEMPT [X]
============================================================
PyTorch Implementation: ‚úì SUCCESS
Triton Implementation:  ‚úì SUCCESS

PyTorch Time: X.XXXXs (X.XXms per run)
Triton Time:  X.XXXXs (X.XXms per run)

üèÜ RESULT: Triton is X.XXx FASTER than PyTorch

‚úÖ SUCCESS: Both implementations completed successfully!
```

## Cycle Continuation
After each success or failure, continue the cycle by generating a new task. The goal is to create a collection of working fused kernel implementations in the data/ folder.